{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "porter = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Cleanup\n",
    "def cleaned_1(text):\n",
    "    #text = re.sub(\"s+\",\" \", text) #Removing extra spaces\n",
    "    #text = re.sub(\"[^-9A-Za-z ]\", \"\" , text) #Punctuations can be removed by using regular expressions.\n",
    "    text = \"\".join([i.lower() for i in text if i not in string.punctuation])\n",
    "    text = re.sub('[-+]?[0-9]+', '', text) #Remove numbers\n",
    "    text = re.sub('\\[[^]]*\\]', '', text) #Remove between square brackets\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text): # 1.2\n",
    "    words = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "\n",
    "    # Stem here only # 1.3\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "\n",
    "    # Lemmatize # 1.4\n",
    "    lemmatized = []\n",
    "    for word in stemmed:\n",
    "        lemmatized.append(lemmatizer.lemmatize(word))\n",
    "    return ' '.join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_text_dict = {}\n",
    "def create_df(root):\n",
    "    file_names = os.listdir(root)\n",
    "    # Create Dictionary for File Name and Text\n",
    "    file_name_and_text = {}\n",
    "    for file in file_names:\n",
    "        with open(root + file, \"r\") as target_file:\n",
    "            file_name_and_text[file] = remove_stopwords(cleaned_1(target_file.read()))\n",
    "    file_data = (pd.DataFrame.from_dict(file_name_and_text, orient='index')\n",
    "                .reset_index().rename(index = str, columns = {'index': 'file_name', 0: 'text'}))\n",
    "    return file_data           \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./op_spam_training_data/\"\n",
    "outer_tags = ['negative_polarity','positive_polarity']\n",
    "inner_tags= ['deceptive_from_MTurk', 'truthful_from_TripAdvisor']\n",
    "\n",
    "df_res_list = []\n",
    "tag = 0 \n",
    "for outer in outer_tags:\n",
    "    for inner in inner_tags:\n",
    "        if not os.path.exists(root + outer + \"/\" + inner):\n",
    "            inner = 'truthful_from_Web'\n",
    "\n",
    "        for i in range(1,5):\n",
    "            loc = root + outer + \"/\" + inner + \"/\" + \"fold\" + str(i) + \"/\"\n",
    "            df_res = create_df(loc)\n",
    "            df_res[\"category\"] = tag\n",
    "            df_res_list.append(df_res)\n",
    "        tag = tag + 1     \n",
    "\n",
    "df = pd.concat(df_res_list)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             file_name                                               text  \\\n",
       "0     d_sofitel_12.txt  husband stay sofitel chicago water tower three...   \n",
       "1     d_sofitel_13.txt  stay sofitel one le pleasur experi chicago upo...   \n",
       "2     d_sofitel_11.txt  stay sofitel husband weekend never stay staff ...   \n",
       "3     d_sofitel_10.txt  stay sofitel chicago water tower hotel coupl w...   \n",
       "4     d_sofitel_14.txt  arriv sofitel chicago water tower hotel greet ...   \n",
       "..                 ...                                                ...   \n",
       "35   t_sheraton_18.txt  gener speak noth bad place would clean issu ch...   \n",
       "36    t_homewood_6.txt  plan stay night famili trip book hotel expect ...   \n",
       "37  t_swissotel_18.txt  stay valentin weekend got th floor direct view...   \n",
       "38    t_homewood_7.txt  read good review book night stay check late bi...   \n",
       "39  t_swissotel_19.txt  stay swissotel three day weekend disappoint se...   \n",
       "\n",
       "    category  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "35         1  \n",
       "36         1  \n",
       "37         1  \n",
       "38         1  \n",
       "39         1  \n",
       "\n",
       "[600 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>d_sofitel_12.txt</td>\n      <td>husband stay sofitel chicago water tower three...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d_sofitel_13.txt</td>\n      <td>stay sofitel one le pleasur experi chicago upo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>d_sofitel_11.txt</td>\n      <td>stay sofitel husband weekend never stay staff ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d_sofitel_10.txt</td>\n      <td>stay sofitel chicago water tower hotel coupl w...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>d_sofitel_14.txt</td>\n      <td>arriv sofitel chicago water tower hotel greet ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>t_sheraton_18.txt</td>\n      <td>gener speak noth bad place would clean issu ch...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>t_homewood_6.txt</td>\n      <td>plan stay night famili trip book hotel expect ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>t_swissotel_18.txt</td>\n      <td>stay valentin weekend got th floor direct view...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>t_homewood_7.txt</td>\n      <td>read good review book night stay check late bi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>t_swissotel_19.txt</td>\n      <td>stay swissotel three day weekend disappoint se...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>600 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "df.head(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i\nme\nmy\nmyself\nwe\nour\nours\nourselves\nyou\nyou're\nyou've\nyou'll\nyou'd\nyour\nyours\nyourself\nyourselves\nhe\nhim\nhis\nhimself\nshe\nshe's\nher\nhers\nherself\nit\nit's\nits\nitself\nthey\nthem\ntheir\ntheirs\nthemselves\nwhat\nwhich\nwho\nwhom\nthis\nthat\nthat'll\nthese\nthose\nam\nis\nare\nwas\nwere\nbe\nbeen\nbeing\nhave\nhas\nhad\nhaving\ndo\ndoes\ndid\ndoing\na\nan\nthe\nand\nbut\nif\nor\nbecause\nas\nuntil\nwhile\nof\nat\nby\nfor\nwith\nabout\nagainst\nbetween\ninto\nthrough\nduring\nbefore\nafter\nabove\nbelow\nto\nfrom\nup\ndown\nin\nout\non\noff\nover\nunder\nagain\nfurther\nthen\nonce\nhere\nthere\nwhen\nwhere\nwhy\nhow\nall\nany\nboth\neach\nfew\nmore\nmost\nother\nsome\nsuch\nno\nnor\nnot\nonly\nown\nsame\nso\nthan\ntoo\nvery\ns\nt\ncan\nwill\njust\ndon\ndon't\nshould\nshould've\nnow\nd\nll\nm\no\nre\nve\ny\nain\naren\naren't\ncouldn\ncouldn't\ndidn\ndidn't\ndoesn\ndoesn't\nhadn\nhadn't\nhasn\nhasn't\nhaven\nhaven't\nisn\nisn't\nma\nmightn\nmightn't\nmustn\nmustn't\nneedn\nneedn't\nshan\nshan't\nshouldn\nshouldn't\nwasn\nwasn't\nweren\nweren't\nwon\nwon't\nwouldn\nwouldn't\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword = stopwords.words('english')\n",
    "for word in stopword:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}